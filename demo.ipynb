{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/abigailhaddad/fedscope_new/blob/main/demo.ipynb)\n\n# OPM Federal Workforce Data: Accessions & Separations Over Time\n\nThis notebook loads federal workforce accession (new hires) and separation (departures) data from HuggingFace and visualizes trends over time.\n\n**No authentication required** - all datasets are public."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install dependencies (for Colab)\n!pip install -q duckdb pandas plotly"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import duckdb\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom datetime import datetime"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Define Dataset URLs\n\nThe data is stored as parquet files on HuggingFace. DuckDB can query them directly via HTTP."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generate all dataset URLs\nHF_USERNAME = \"abigailhaddad\"\nBASE_URL = f\"https://huggingface.co/datasets/{HF_USERNAME}\"\n\ndef generate_months(start_year=2021, start_month=1, end_year=2025, end_month=11):\n    \"\"\"Generate list of YYYYMM strings.\"\"\"\n    months = []\n    for year in range(start_year, end_year + 1):\n        for month in range(1, 13):\n            if year == start_year and month < start_month:\n                continue\n            if year == end_year and month > end_month:\n                break\n            months.append(f\"{year}{month:02d}\")\n    return months\n\nmonths = generate_months()\n\n# Build URLs for each dataset\naccession_urls = [f\"{BASE_URL}/opm-federal-accessions-{m}/resolve/main/data.parquet\" for m in months]\nseparation_urls = [f\"{BASE_URL}/opm-federal-separations-{m}/resolve/main/data.parquet\" for m in months]\n\nprint(f\"Generated {len(accession_urls)} accession URLs\")\nprint(f\"Generated {len(separation_urls)} separation URLs\")\nprint(f\"\\nExample: {accession_urls[0]}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verify datasets exist by checking a few\ndef check_url(url):\n    \"\"\"Quick check if parquet URL is accessible.\"\"\"\n    try:\n        duckdb.sql(f\"SELECT 1 FROM '{url}' LIMIT 1\")\n        return True\n    except:\n        return False\n\n# Check first and last of each type\nprint(\"Checking dataset availability...\")\nprint(f\"  First accession ({months[0]}): {'OK' if check_url(accession_urls[0]) else 'MISSING'}\")\nprint(f\"  Last accession ({months[-1]}): {'OK' if check_url(accession_urls[-1]) else 'MISSING'}\")\nprint(f\"  First separation ({months[0]}): {'OK' if check_url(separation_urls[0]) else 'MISSING'}\")\nprint(f\"  Last separation ({months[-1]}): {'OK' if check_url(separation_urls[-1]) else 'MISSING'}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Load All Data with DuckDB\n\nDuckDB reads parquet files directly via HTTP - no download needed. This is much faster than the datasets library."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%time\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\ndef get_count(args):\n    \"\"\"Get row count for a single parquet URL.\"\"\"\n    url, month = args\n    try:\n        # Each thread needs its own connection\n        conn = duckdb.connect()\n        result = conn.sql(f\"SELECT COUNT(*) FROM '{url}'\").fetchone()\n        conn.close()\n        return {'month': month, 'date': datetime.strptime(month, '%Y%m'), 'count': result[0]}\n    except:\n        return None\n\ndef load_counts_parallel(urls, months, data_type, max_workers=16):\n    \"\"\"Load counts in parallel using thread pool.\"\"\"\n    counts = []\n    errors = []\n    \n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        futures = {executor.submit(get_count, (url, month)): month \n                   for url, month in zip(urls, months)}\n        \n        for future in as_completed(futures):\n            result = future.result()\n            if result:\n                counts.append(result)\n            else:\n                errors.append(futures[future])\n    \n    if errors:\n        print(f\"  Missing {data_type} months: {sorted(errors)}\")\n    else:\n        print(f\"  All {len(counts)} {data_type} months loaded!\")\n    \n    # Sort by month\n    return pd.DataFrame(counts).sort_values('month').reset_index(drop=True)\n\nprint(\"Loading accessions and separations in parallel...\")\nacc_df = load_counts_parallel(accession_urls, months, \"accession\")\nsep_df = load_counts_parallel(separation_urls, months, \"separation\")\n\nprint(f\"\\nLoaded {len(acc_df)} accession months, {len(sep_df)} separation months\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plot Accessions vs Separations Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig = go.Figure()\n\nfig.add_trace(go.Scatter(\n    x=acc_df['date'], \n    y=acc_df['count'],\n    mode='lines+markers',\n    name='Accessions (New Hires)',\n    line=dict(color='#2ecc71', width=2),\n    marker=dict(size=6),\n    hovertemplate='%{x|%b %Y}<br>%{y:,.0f} new hires<extra></extra>'\n))\n\nfig.add_trace(go.Scatter(\n    x=sep_df['date'], \n    y=sep_df['count'],\n    mode='lines+markers',\n    name='Separations (Departures)',\n    line=dict(color='#e74c3c', width=2),\n    marker=dict(size=6),\n    hovertemplate='%{x|%b %Y}<br>%{y:,.0f} departures<extra></extra>'\n))\n\nfig.update_layout(\n    title='Federal Workforce: Monthly Accessions vs Separations (2021-2025)',\n    xaxis_title='Month',\n    yaxis_title='Count',\n    hovermode='x unified',\n    template='plotly_white',\n    legend=dict(\n        orientation='h',\n        yanchor='bottom',\n        y=1.02,\n        xanchor='right',\n        x=1\n    ),\n    yaxis=dict(tickformat=','),\n    height=500\n)\n\nfig.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Net change (accessions - separations)\nmerged = acc_df.merge(sep_df, on=['month', 'date'], suffixes=('_acc', '_sep'))\nmerged['net_change'] = merged['count_acc'] - merged['count_sep']\nmerged['color'] = merged['net_change'].apply(lambda x: '#2ecc71' if x > 0 else '#e74c3c')\n\nfig = go.Figure()\n\nfig.add_trace(go.Bar(\n    x=merged['date'],\n    y=merged['net_change'],\n    marker_color=merged['color'],\n    hovertemplate='%{x|%b %Y}<br>Net: %{y:+,.0f}<extra></extra>'\n))\n\nfig.add_hline(y=0, line_width=1, line_color='black')\n\nfig.update_layout(\n    title='Federal Workforce: Monthly Net Change (Accessions - Separations)',\n    xaxis_title='Month',\n    yaxis_title='Net Change',\n    template='plotly_white',\n    yaxis=dict(tickformat=','),\n    height=450,\n    showlegend=False\n)\n\nfig.show()\n\nprint(f\"\\nTotal accessions: {merged['count_acc'].sum():,}\")\nprint(f\"Total separations: {merged['count_sep'].sum():,}\")\nprint(f\"Net change: {merged['net_change'].sum():+,}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explore the Data Structure\n",
    "\n",
    "Let's look at what columns are available in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Inspect columns using DuckDB\nprint(\"Accessions columns:\")\nacc_cols = duckdb.sql(f\"DESCRIBE SELECT * FROM '{accession_urls[0]}'\").df()\nprint(acc_cols['column_name'].tolist())\n\nprint(\"\\nSeparations columns:\")\nsep_cols = duckdb.sql(f\"DESCRIBE SELECT * FROM '{separation_urls[0]}'\").df()\nprint(sep_cols['column_name'].tolist())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Show sample data\nprint(\"Sample accession records:\")\nduckdb.sql(f\"SELECT * FROM '{accession_urls[0]}' LIMIT 5\").df()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}