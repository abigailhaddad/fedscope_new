{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/abigailhaddad/fedscope_new/blob/main/demo.ipynb)\n\n# OPM Federal Workforce Data: Accessions & Separations Over Time\n\nThis notebook loads federal workforce accession (new hires) and separation (departures) data from HuggingFace and visualizes trends over time.\n\n**No authentication required** - all datasets are public."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install dependencies (for Colab)\n!pip install -q duckdb pandas matplotlib"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import duckdb\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom datetime import datetime"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Define Dataset URLs\n\nThe data is stored as parquet files on HuggingFace. DuckDB can query them directly via HTTP."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generate all dataset URLs\nHF_USERNAME = \"abigailhaddad\"\nBASE_URL = f\"https://huggingface.co/datasets/{HF_USERNAME}\"\n\ndef generate_months(start_year=2021, start_month=1, end_year=2025, end_month=11):\n    \"\"\"Generate list of YYYYMM strings.\"\"\"\n    months = []\n    for year in range(start_year, end_year + 1):\n        for month in range(1, 13):\n            if year == start_year and month < start_month:\n                continue\n            if year == end_year and month > end_month:\n                break\n            months.append(f\"{year}{month:02d}\")\n    return months\n\nmonths = generate_months()\n\n# Build URLs for each dataset\naccession_urls = [f\"{BASE_URL}/opm-federal-accessions-{m}/resolve/main/data.parquet\" for m in months]\nseparation_urls = [f\"{BASE_URL}/opm-federal-separations-{m}/resolve/main/data.parquet\" for m in months]\n\nprint(f\"Generated {len(accession_urls)} accession URLs\")\nprint(f\"Generated {len(separation_urls)} separation URLs\")\nprint(f\"\\nExample: {accession_urls[0]}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verify datasets exist by checking a few\ndef check_url(url):\n    \"\"\"Quick check if parquet URL is accessible.\"\"\"\n    try:\n        duckdb.sql(f\"SELECT 1 FROM '{url}' LIMIT 1\")\n        return True\n    except:\n        return False\n\n# Check first and last of each type\nprint(\"Checking dataset availability...\")\nprint(f\"  First accession ({months[0]}): {'OK' if check_url(accession_urls[0]) else 'MISSING'}\")\nprint(f\"  Last accession ({months[-1]}): {'OK' if check_url(accession_urls[-1]) else 'MISSING'}\")\nprint(f\"  First separation ({months[0]}): {'OK' if check_url(separation_urls[0]) else 'MISSING'}\")\nprint(f\"  Last separation ({months[-1]}): {'OK' if check_url(separation_urls[-1]) else 'MISSING'}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Load All Data with DuckDB\n\nDuckDB reads parquet files directly via HTTP - no download needed. This is much faster than the datasets library."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%time\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\ndef get_count(args):\n    \"\"\"Get row count for a single parquet URL.\"\"\"\n    url, month = args\n    try:\n        # Each thread needs its own connection\n        conn = duckdb.connect()\n        result = conn.sql(f\"SELECT COUNT(*) FROM '{url}'\").fetchone()\n        conn.close()\n        return {'month': month, 'date': datetime.strptime(month, '%Y%m'), 'count': result[0]}\n    except:\n        return None\n\ndef load_counts_parallel(urls, months, data_type, max_workers=16):\n    \"\"\"Load counts in parallel using thread pool.\"\"\"\n    counts = []\n    errors = []\n    \n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        futures = {executor.submit(get_count, (url, month)): month \n                   for url, month in zip(urls, months)}\n        \n        for future in as_completed(futures):\n            result = future.result()\n            if result:\n                counts.append(result)\n            else:\n                errors.append(futures[future])\n    \n    if errors:\n        print(f\"  Missing {data_type} months: {sorted(errors)}\")\n    else:\n        print(f\"  All {len(counts)} {data_type} months loaded!\")\n    \n    # Sort by month\n    return pd.DataFrame(counts).sort_values('month').reset_index(drop=True)\n\nprint(\"Loading accessions and separations in parallel...\")\nacc_df = load_counts_parallel(accession_urls, months, \"accession\")\nsep_df = load_counts_parallel(separation_urls, months, \"separation\")\n\nprint(f\"\\nLoaded {len(acc_df)} accession months, {len(sep_df)} separation months\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plot Accessions vs Separations Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "ax.plot(acc_df['date'], acc_df['count'], marker='o', markersize=3, label='Accessions (New Hires)', color='#2ecc71')\n",
    "ax.plot(sep_df['date'], sep_df['count'], marker='o', markersize=3, label='Separations (Departures)', color='#e74c3c')\n",
    "\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Federal Workforce: Monthly Accessions vs Separations (2021-2025)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Format y-axis with commas\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Net change (accessions - separations)\n",
    "merged = acc_df.merge(sep_df, on=['month', 'date'], suffixes=('_acc', '_sep'))\n",
    "merged['net_change'] = merged['count_acc'] - merged['count_sep']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "\n",
    "colors = ['#2ecc71' if x > 0 else '#e74c3c' for x in merged['net_change']]\n",
    "ax.bar(merged['date'], merged['net_change'], color=colors, width=20)\n",
    "\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('Net Change (Accessions - Separations)')\n",
    "ax.set_title('Federal Workforce: Monthly Net Change')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTotal accessions: {merged['count_acc'].sum():,}\")\n",
    "print(f\"Total separations: {merged['count_sep'].sum():,}\")\n",
    "print(f\"Net change: {merged['net_change'].sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explore the Data Structure\n",
    "\n",
    "Let's look at what columns are available in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Inspect columns using DuckDB\nprint(\"Accessions columns:\")\nacc_cols = duckdb.sql(f\"DESCRIBE SELECT * FROM '{accession_urls[0]}'\").df()\nprint(acc_cols['column_name'].tolist())\n\nprint(\"\\nSeparations columns:\")\nsep_cols = duckdb.sql(f\"DESCRIBE SELECT * FROM '{separation_urls[0]}'\").df()\nprint(sep_cols['column_name'].tolist())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Show sample data\nprint(\"Sample accession records:\")\nduckdb.sql(f\"SELECT * FROM '{accession_urls[0]}' LIMIT 5\").df()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}