{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/abigailhaddad/fedscope_new/blob/main/demo.ipynb)\n\n# OPM Federal Workforce Data: Accessions & Separations Over Time\n\nThis notebook loads federal workforce accession (new hires) and separation (departures) data from HuggingFace and visualizes trends over time.\n\n**No authentication required** - all datasets are public."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install dependencies (for Colab)\n!pip install -q duckdb pandas plotly"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import duckdb\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom datetime import datetime"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Define Dataset URLs\n\nThe data is stored as parquet files on HuggingFace. DuckDB can query them directly via HTTP."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generate all dataset URLs\nHF_USERNAME = \"abigailhaddad\"\nBASE_URL = f\"https://huggingface.co/datasets/{HF_USERNAME}\"\n\ndef generate_months(start_year=2021, start_month=1, end_year=2025, end_month=11):\n    \"\"\"Generate list of YYYYMM strings.\"\"\"\n    months = []\n    for year in range(start_year, end_year + 1):\n        for month in range(1, 13):\n            if year == start_year and month < start_month:\n                continue\n            if year == end_year and month > end_month:\n                break\n            months.append(f\"{year}{month:02d}\")\n    return months\n\nmonths = generate_months()\n\n# Build URLs for each dataset\naccession_urls = [f\"{BASE_URL}/opm-federal-accessions-{m}/resolve/main/data.parquet\" for m in months]\nseparation_urls = [f\"{BASE_URL}/opm-federal-separations-{m}/resolve/main/data.parquet\" for m in months]\n\nprint(f\"Generated {len(accession_urls)} accession URLs\")\nprint(f\"Generated {len(separation_urls)} separation URLs\")\nprint(f\"\\nExample: {accession_urls[0]}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verify datasets exist by checking a few\ndef check_url(url):\n    \"\"\"Quick check if parquet URL is accessible.\"\"\"\n    try:\n        duckdb.sql(f\"SELECT 1 FROM '{url}' LIMIT 1\")\n        return True\n    except:\n        return False\n\n# Check first and last of each type\nprint(\"Checking dataset availability...\")\nprint(f\"  First accession ({months[0]}): {'OK' if check_url(accession_urls[0]) else 'MISSING'}\")\nprint(f\"  Last accession ({months[-1]}): {'OK' if check_url(accession_urls[-1]) else 'MISSING'}\")\nprint(f\"  First separation ({months[0]}): {'OK' if check_url(separation_urls[0]) else 'MISSING'}\")\nprint(f\"  Last separation ({months[-1]}): {'OK' if check_url(separation_urls[-1]) else 'MISSING'}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Load All Data with DuckDB\n\nDuckDB reads parquet files directly via HTTP - no download needed. This is much faster than the datasets library."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%time\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\ndef get_count(args):\n    \"\"\"Get row count for a single parquet URL.\"\"\"\n    url, month = args\n    try:\n        # Each thread needs its own connection\n        conn = duckdb.connect()\n        result = conn.sql(f\"SELECT COUNT(*) FROM '{url}'\").fetchone()\n        conn.close()\n        return {'month': month, 'date': datetime.strptime(month, '%Y%m'), 'count': result[0]}\n    except:\n        return None\n\ndef load_counts_parallel(urls, months, data_type, max_workers=16):\n    \"\"\"Load counts in parallel using thread pool.\"\"\"\n    counts = []\n    errors = []\n    \n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        futures = {executor.submit(get_count, (url, month)): month \n                   for url, month in zip(urls, months)}\n        \n        for future in as_completed(futures):\n            result = future.result()\n            if result:\n                counts.append(result)\n            else:\n                errors.append(futures[future])\n    \n    if errors:\n        print(f\"  Missing {data_type} months: {sorted(errors)}\")\n    else:\n        print(f\"  All {len(counts)} {data_type} months loaded!\")\n    \n    # Sort by month\n    return pd.DataFrame(counts).sort_values('month').reset_index(drop=True)\n\nprint(\"Loading accessions and separations in parallel...\")\nacc_df = load_counts_parallel(accession_urls, months, \"accession\")\nsep_df = load_counts_parallel(separation_urls, months, \"separation\")\n\nprint(f\"\\nLoaded {len(acc_df)} accession months, {len(sep_df)} separation months\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plot Accessions vs Separations Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig = go.Figure()\n\nfig.add_trace(go.Scatter(\n    x=acc_df['date'], \n    y=acc_df['count'],\n    mode='lines+markers',\n    name='Accessions (New Hires)',\n    line=dict(color='#2ecc71', width=2),\n    marker=dict(size=6),\n    hovertemplate='%{x|%b %Y}<br>%{y:,.0f} new hires<extra></extra>'\n))\n\nfig.add_trace(go.Scatter(\n    x=sep_df['date'], \n    y=sep_df['count'],\n    mode='lines+markers',\n    name='Separations (Departures)',\n    line=dict(color='#e74c3c', width=2),\n    marker=dict(size=6),\n    hovertemplate='%{x|%b %Y}<br>%{y:,.0f} departures<extra></extra>'\n))\n\nfig.update_layout(\n    title='Federal Workforce: Monthly Accessions vs Separations (2021-2025)',\n    xaxis_title='Month',\n    yaxis_title='Count',\n    hovermode='x unified',\n    template='plotly_white',\n    legend=dict(\n        orientation='h',\n        yanchor='bottom',\n        y=1.02,\n        xanchor='right',\n        x=1\n    ),\n    yaxis=dict(tickformat=','),\n    height=500\n)\n\nfig.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Net change (accessions - separations)\nmerged = acc_df.merge(sep_df, on=['month', 'date'], suffixes=('_acc', '_sep'))\nmerged['net_change'] = merged['count_acc'] - merged['count_sep']\nmerged['color'] = merged['net_change'].apply(lambda x: '#2ecc71' if x > 0 else '#e74c3c')\n\nfig = go.Figure()\n\nfig.add_trace(go.Bar(\n    x=merged['date'],\n    y=merged['net_change'],\n    marker_color=merged['color'],\n    hovertemplate='%{x|%b %Y}<br>Net: %{y:+,.0f}<extra></extra>'\n))\n\nfig.add_hline(y=0, line_width=1, line_color='black')\n\nfig.update_layout(\n    title='Federal Workforce: Monthly Net Change (Accessions - Separations)',\n    xaxis_title='Month',\n    yaxis_title='Net Change',\n    template='plotly_white',\n    yaxis=dict(tickformat=','),\n    height=450,\n    showlegend=False\n)\n\nfig.show()\n\nprint(f\"\\nTotal accessions: {merged['count_acc'].sum():,}\")\nprint(f\"Total separations: {merged['count_sep'].sum():,}\")\nprint(f\"Net change: {merged['net_change'].sum():+,}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explore the Data Structure\n",
    "\n",
    "Let's look at what columns are available in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Inspect columns using DuckDB\nprint(\"Accessions columns:\")\nacc_cols = duckdb.sql(f\"DESCRIBE SELECT * FROM '{accession_urls[0]}'\").df()\nprint(acc_cols['column_name'].tolist())\n\nprint(\"\\nSeparations columns:\")\nsep_cols = duckdb.sql(f\"DESCRIBE SELECT * FROM '{separation_urls[0]}'\").df()\nprint(sep_cols['column_name'].tolist())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Show sample data\nprint(\"Sample accession records:\")\nduckdb.sql(f\"SELECT * FROM '{accession_urls[0]}' LIMIT 5\").df()"
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Data Quality Analysis\n\nSome fields have missing, redacted, or placeholder values that can affect analysis.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Analyze data quality across all accession data\n# Using just the most recent month for speed - patterns are consistent\n\nsample_url = accession_urls[-1]  # Most recent month\n\nquality_issues = []\n\n# Check key columns for problematic values\nchecks = {\n    'duty_station_state': ['REDACTED', 'NO DATA REPORTED', 'UNSPECIFIED'],\n    'education_level': ['UNSPECIFIED', 'NO DATA REPORTED'],\n    'occupational_series': ['UNSPECIFIED', 'NO DATA REPORTED'],\n    'agency': ['UNSPECIFIED'],\n    'stem_occupation': ['UNSPECIFIED', 'ALL OTHER OCCUPATIONS'],\n    'supervisory_status': ['ALL OTHER POSITIONS'],\n}\n\nprint(\"=== DATA QUALITY ISSUES (sample month) ===\\n\")\n\nfor col, bad_values in checks.items():\n    conditions = \" OR \".join([f\"{col} = '{v}'\" for v in bad_values])\n    \n    result = duckdb.sql(f\"\"\"\n        SELECT \n            {col} as value,\n            SUM(CAST(count AS INTEGER)) as people\n        FROM '{sample_url}'\n        WHERE {conditions}\n        GROUP BY {col}\n        ORDER BY people DESC\n    \"\"\").df()\n    \n    if len(result) > 0:\n        total = result['people'].sum()\n        total_all = duckdb.sql(f\"SELECT SUM(CAST(count AS INTEGER)) FROM '{sample_url}'\").fetchone()[0]\n        pct = (total / total_all) * 100\n        \n        print(f\"ðŸ“ {col}: {total:,.0f} people ({pct:.1f}%) have unusable values\")\n        for _, row in result.iterrows():\n            print(f\"   â€¢ '{row['value']}': {row['people']:,.0f}\")\n        print()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 6. Interactive Filtering\n\nFilter accessions and separations by agency, state, occupation, etc. and view the trends.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Get available filter options from a sample month\nsample_url = accession_urls[-1]\n\ndef get_options(col):\n    \"\"\"Get unique values for a column, sorted by frequency.\"\"\"\n    result = duckdb.sql(f\"\"\"\n        SELECT {col} as value, SUM(CAST(count AS INTEGER)) as n\n        FROM '{sample_url}'\n        WHERE {col} IS NOT NULL AND {col} != ''\n        GROUP BY {col}\n        ORDER BY n DESC\n    \"\"\").df()\n    return ['All'] + result['value'].tolist()\n\n# Cache filter options\nfilter_options = {\n    'agency': get_options('agency'),\n    'duty_station_state': get_options('duty_station_state'),\n    'occupational_group': get_options('occupational_group'),\n    'age_bracket': get_options('age_bracket'),\n    'education_level': get_options('education_level'),\n}\n\nprint(\"Filter options loaded!\")\nprint(f\"  Agencies: {len(filter_options['agency'])-1}\")\nprint(f\"  States: {len(filter_options['duty_station_state'])-1}\")\nprint(f\"  Occupational Groups: {len(filter_options['occupational_group'])-1}\")\nprint(f\"  Age Brackets: {len(filter_options['age_bracket'])-1}\")\nprint(f\"  Education Levels: {len(filter_options['education_level'])-1}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import ipywidgets as widgets\nfrom IPython.display import display, clear_output\n\n# Create filter widgets\nagency_dropdown = widgets.Dropdown(options=filter_options['agency'], value='All', description='Agency:')\nstate_dropdown = widgets.Dropdown(options=filter_options['duty_station_state'], value='All', description='State:')\nocc_dropdown = widgets.Dropdown(options=filter_options['occupational_group'], value='All', description='Occ Group:')\n\n# Output area for results\noutput = widgets.Output()\ndownload_output = widgets.Output()\n\ndef query_filtered_data(data_type, agency, state, occ_group):\n    \"\"\"Query all months with filters applied.\"\"\"\n    urls = accession_urls if data_type == 'accessions' else separation_urls\n    \n    # Build WHERE clause\n    conditions = []\n    if agency != 'All':\n        conditions.append(f\"agency = '{agency}'\")\n    if state != 'All':\n        conditions.append(f\"duty_station_state = '{state}'\")\n    if occ_group != 'All':\n        conditions.append(f\"occupational_group = '{occ_group}'\")\n    \n    where_clause = \"WHERE \" + \" AND \".join(conditions) if conditions else \"\"\n    \n    results = []\n    for url, month in zip(urls, months):\n        try:\n            conn = duckdb.connect()\n            result = conn.sql(f\"\"\"\n                SELECT SUM(CAST(count AS INTEGER)) as total\n                FROM '{url}'\n                {where_clause}\n            \"\"\").fetchone()\n            conn.close()\n            if result[0]:\n                results.append({\n                    'month': month,\n                    'date': datetime.strptime(month, '%Y%m'),\n                    'count': result[0]\n                })\n        except:\n            pass\n    \n    return pd.DataFrame(results)\n\ndef update_chart(change=None):\n    \"\"\"Update the chart based on filter selections.\"\"\"\n    with output:\n        clear_output(wait=True)\n        print(\"Loading filtered data...\")\n        \n        # Query both datasets in parallel\n        from concurrent.futures import ThreadPoolExecutor\n        with ThreadPoolExecutor(max_workers=2) as executor:\n            acc_future = executor.submit(\n                query_filtered_data, 'accessions', \n                agency_dropdown.value, state_dropdown.value, occ_dropdown.value\n            )\n            sep_future = executor.submit(\n                query_filtered_data, 'separations',\n                agency_dropdown.value, state_dropdown.value, occ_dropdown.value\n            )\n            filtered_acc = acc_future.result()\n            filtered_sep = sep_future.result()\n        \n        clear_output(wait=True)\n        \n        if len(filtered_acc) == 0 and len(filtered_sep) == 0:\n            print(\"No data found for these filters.\")\n            return\n        \n        # Create chart\n        fig = go.Figure()\n        \n        if len(filtered_acc) > 0:\n            fig.add_trace(go.Scatter(\n                x=filtered_acc['date'], y=filtered_acc['count'],\n                mode='lines+markers', name='Accessions',\n                line=dict(color='#2ecc71', width=2),\n                hovertemplate='%{x|%b %Y}<br>%{y:,.0f}<extra></extra>'\n            ))\n        \n        if len(filtered_sep) > 0:\n            fig.add_trace(go.Scatter(\n                x=filtered_sep['date'], y=filtered_sep['count'],\n                mode='lines+markers', name='Separations',\n                line=dict(color='#e74c3c', width=2),\n                hovertemplate='%{x|%b %Y}<br>%{y:,.0f}<extra></extra>'\n            ))\n        \n        # Build title\n        filters = []\n        if agency_dropdown.value != 'All':\n            filters.append(agency_dropdown.value[:30])\n        if state_dropdown.value != 'All':\n            filters.append(state_dropdown.value)\n        if occ_dropdown.value != 'All':\n            filters.append(occ_dropdown.value[:30])\n        \n        title = \"Filtered: \" + \", \".join(filters) if filters else \"All Federal Workforce\"\n        \n        fig.update_layout(\n            title=title,\n            xaxis_title='Month', yaxis_title='Count',\n            template='plotly_white', height=450,\n            yaxis=dict(tickformat=','),\n            hovermode='x unified'\n        )\n        fig.show()\n        \n        # Show totals\n        acc_total = filtered_acc['count'].sum() if len(filtered_acc) > 0 else 0\n        sep_total = filtered_sep['count'].sum() if len(filtered_sep) > 0 else 0\n        print(f\"\\nTotal accessions: {acc_total:,.0f}\")\n        print(f\"Total separations: {sep_total:,.0f}\")\n        print(f\"Net change: {acc_total - sep_total:+,.0f}\")\n    \n    # Update download data\n    with download_output:\n        clear_output(wait=True)\n        if len(filtered_acc) > 0 or len(filtered_sep) > 0:\n            merged = pd.merge(\n                filtered_acc.rename(columns={'count': 'accessions'}),\n                filtered_sep.rename(columns={'count': 'separations'}),\n                on=['month', 'date'], how='outer'\n            ).fillna(0)\n            merged['net_change'] = merged['accessions'] - merged['separations']\n            print(\"ðŸ“¥ Data ready for download (right-click table â†’ Save as CSV):\")\n            display(merged[['month', 'accessions', 'separations', 'net_change']])\n\n# Connect widgets to update function\nagency_dropdown.observe(update_chart, names='value')\nstate_dropdown.observe(update_chart, names='value')\nocc_dropdown.observe(update_chart, names='value')\n\n# Display widgets\nprint(\"Select filters and the chart will update automatically:\")\ndisplay(widgets.HBox([agency_dropdown, state_dropdown, occ_dropdown]))\ndisplay(output)\ndisplay(download_output)\n\n# Initial load\nupdate_chart()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}